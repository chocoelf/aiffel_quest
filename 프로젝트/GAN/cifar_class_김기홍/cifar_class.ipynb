{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1회 이상 실행시 오류가 발생합니다.\n",
    "! mkdir -p /home/faith/workspace/cifar/generated_samples\n",
    "! mkdir -p /home/faith/workspace/cifar/training_checkpoints\n",
    "! mkdir -p /home/faith/workspace/cifar/training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 14:47:42.260850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-21 14:47:42.274130: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-21 14:47:42.277806: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-21 14:47:42.287674: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-21 14:47:43.056520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724219265.808530   30730 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724219265.912539   30730 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724219265.912586   30730 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724219265.915043   30730 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724219265.915111   30730 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724219265.915134   30730 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724219266.067154   30730 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724219266.067222   30730 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-21 14:47:46.067232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1724219266.067272   30730 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-21 14:47:46.067291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10157 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/home/faith/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-08-21 14:47:49.391284: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-21 14:47:50.230718: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8902\n",
      "W0000 00:00:1724219270.281483   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.319978   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.321453   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.323105   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.324605   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.326182   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.327776   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.329772   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.331505   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.333402   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.335385   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.340030   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.342192   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.346223   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.349131   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.351467   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.354134   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.365246   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.368340   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.886191   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.890192   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.900137   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.904792   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.908486   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.914128   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.936189   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.949458   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.959725   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.967708   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219270.998388   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.000700   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.002859   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.005015   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.007204   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.009258   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.016294   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.018930   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.021760   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.024602   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.027436   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.030622   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.033849   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.037474   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.041289   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.045168   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.049682   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.053709   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.057865   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.259098   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.261610   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.266763   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.270502   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.275233   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.278600   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.301647   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.305343   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.388638   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.391216   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.394258   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.397114   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.400608   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.403547   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.407184   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.410213   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.413996   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.417160   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.421748   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.425320   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.426409   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.427478   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.428765   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.432638   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.435022   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.437142   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.446235   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.467062   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.468536   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.470184   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.471975   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.473962   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.476303   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.478440   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.480555   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.482818   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.485451   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.552397   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.559856   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.561694   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.563504   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.565500   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.569633   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.572950   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.575945   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.584913   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.639284   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.640365   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.641314   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.642227   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.643210   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.644105   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.645085   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.646084   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.647037   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.647981   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.648948   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.649882   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.651212   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.652309   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.653374   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.654786   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.656141   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.657277   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.658539   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.663270   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.664330   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.665477   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.666736   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.668094   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.669311   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.670703   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.671930   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.673319   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.674744   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.685251   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.694338   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.699083   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.703926   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.708605   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.714008   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.719544   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.724639   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.729779   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.733165   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.739560   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.745864   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.751304   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.758585   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.767287   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.776283   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.781933   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.790151   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.798848   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.809105   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.816048   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.826557   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.830403   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.834992   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.840364   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.849531   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.856367   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.863174   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.871705   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.875247   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.878256   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.887192   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.895477   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219271.905296   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.119504   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.120002   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.122070   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.123193   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.126102   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.127250   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.128948   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.130090   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.133105   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.134100   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.136795   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.137483   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.143944   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.144684   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.148466   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.149589   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.153539   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.154676   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.157917   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.158609   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.161399   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.163209   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.167955   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.170619   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.172414   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.173095   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.174487   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.175982   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.177974   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.179365   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.181500   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.182399   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.185044   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.186028   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.188038   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.189924   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.192800   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.199001   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.202323   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.205019   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.207224   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.207589   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.208895   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.209956   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.211274   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.212713   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.213717   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.214653   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.216011   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.218414   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.220293   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.221053   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.222513   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.224015   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.225798   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.234381   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.235915   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.239138   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.241290   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.243308   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.249254   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.250222   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.251930   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.253550   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.254560   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.256891   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.258136   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.259437   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.261272   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.263040   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.265035   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.267534   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.268856   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.270596   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.272290   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.273040   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.274411   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.275917   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.277571   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.278729   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.280770   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.282125   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.283876   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.286235   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.287072   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.289072   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.290343   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.292184   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.293962   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.296049   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.297744   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.300146   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.301801   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.303519   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.305767   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.310396   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.312381   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.314700   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.316850   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.318769   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.320524   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.321164   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.322836   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.323772   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.325123   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.327177   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.328076   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.329584   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.330828   30812 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.332490   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.335444   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.337207   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.338907   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.347750   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.363671   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.364615   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.365549   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.366469   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.367385   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.368301   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.369215   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.370182   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.371137   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.372067   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.373088   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.373921   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.374883   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.375826   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.376694   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.377658   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.378611   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.379531   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.380455   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.387374   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.390862   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.391852   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.392838   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.393779   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.394761   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.395734   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.396787   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.397808   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.399641   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.400752   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.402209   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.411690   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.413470   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.415492   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.417646   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.420207   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.422518   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.425012   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.427300   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.429546   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.431173   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.433781   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.436212   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.438296   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.441040   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.444058   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.447265   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.449754   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.452763   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.455786   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.459371   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.462079   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.468133   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.469476   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.471490   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.473849   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.476958   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.479449   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.482221   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.485307   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.487007   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.488608   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.491804   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.494641   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.498032   30813 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-08-21 14:48:01.503368: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gen Loss: 1.0001, Disc Loss: 1.1038, Time: 14.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1724219281.522748   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.524160   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.525327   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.527695   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.528949   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.530599   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.532326   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.541167   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.542054   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.543085   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.543985   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.545123   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.546293   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.547511   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.550037   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.556195   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.557075   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.558004   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.558786   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.559550   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.560612   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.561518   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.562523   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219281.571147   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-08-21 14:48:10.706033: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Gen Loss: 1.5230, Disc Loss: 0.8244, Time: 8.73 sec\n",
      "Epoch 3, Gen Loss: 1.8970, Disc Loss: 0.7115, Time: 10.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 14:48:30.596756: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Gen Loss: 2.0344, Disc Loss: 0.6009, Time: 8.66 sec\n",
      "Epoch 5, Gen Loss: 1.8278, Disc Loss: 0.7998, Time: 8.64 sec\n",
      "Epoch 6, Gen Loss: 1.8765, Disc Loss: 0.6351, Time: 10.68 sec\n",
      "Epoch 7, Gen Loss: 2.2010, Disc Loss: 0.7052, Time: 8.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 14:49:08.535165: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Gen Loss: 1.8988, Disc Loss: 0.7333, Time: 8.60 sec\n",
      "Epoch 9, Gen Loss: 1.5982, Disc Loss: 0.8725, Time: 8.78 sec\n",
      "Epoch 10, Gen Loss: 2.0045, Disc Loss: 0.7463, Time: 10.67 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Gen Loss: 2.4421, Disc Loss: 0.6073, Time: 8.72 sec\n",
      "Epoch 12, Gen Loss: 1.7949, Disc Loss: 0.8472, Time: 8.64 sec\n",
      "Epoch 13, Gen Loss: 1.6725, Disc Loss: 0.8364, Time: 10.74 sec\n",
      "Epoch 14, Gen Loss: 1.6342, Disc Loss: 0.9172, Time: 8.76 sec\n",
      "Epoch 15, Gen Loss: 1.4846, Disc Loss: 1.0551, Time: 9.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 14:50:25.786524: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Gen Loss: 1.2485, Disc Loss: 1.0573, Time: 8.75 sec\n",
      "Epoch 17, Gen Loss: 1.2669, Disc Loss: 1.0316, Time: 10.71 sec\n",
      "Epoch 18, Gen Loss: 1.3798, Disc Loss: 0.9872, Time: 8.72 sec\n",
      "Epoch 19, Gen Loss: 1.3781, Disc Loss: 1.0025, Time: 8.65 sec\n",
      "Epoch 20, Gen Loss: 1.5877, Disc Loss: 0.9138, Time: 10.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Gen Loss: 1.6626, Disc Loss: 0.9213, Time: 8.83 sec\n",
      "Epoch 22, Gen Loss: 1.6411, Disc Loss: 0.8676, Time: 8.78 sec\n",
      "Epoch 23, Gen Loss: 1.6338, Disc Loss: 0.9213, Time: 8.89 sec\n",
      "Epoch 24, Gen Loss: 1.5834, Disc Loss: 0.9235, Time: 10.98 sec\n",
      "Epoch 25, Gen Loss: 1.6496, Disc Loss: 0.9220, Time: 8.83 sec\n",
      "Epoch 26, Gen Loss: 1.5289, Disc Loss: 0.9054, Time: 8.76 sec\n",
      "Epoch 27, Gen Loss: 1.3685, Disc Loss: 1.0368, Time: 10.57 sec\n",
      "Epoch 28, Gen Loss: 1.4816, Disc Loss: 0.9007, Time: 10.97 sec\n",
      "Epoch 29, Gen Loss: 1.4932, Disc Loss: 1.0473, Time: 10.82 sec\n",
      "Epoch 30, Gen Loss: 1.3512, Disc Loss: 0.9955, Time: 13.07 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Gen Loss: 1.4000, Disc Loss: 1.0216, Time: 9.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 14:53:08.573288: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Gen Loss: 1.3122, Disc Loss: 1.0437, Time: 8.59 sec\n",
      "Epoch 33, Gen Loss: 1.3135, Disc Loss: 1.1166, Time: 8.68 sec\n",
      "Epoch 34, Gen Loss: 1.4088, Disc Loss: 1.0256, Time: 11.13 sec\n",
      "Epoch 35, Gen Loss: 1.3790, Disc Loss: 1.0433, Time: 8.70 sec\n",
      "Epoch 36, Gen Loss: 1.3004, Disc Loss: 1.1020, Time: 8.69 sec\n",
      "Epoch 37, Gen Loss: 1.4525, Disc Loss: 0.9619, Time: 10.82 sec\n",
      "Epoch 38, Gen Loss: 1.3548, Disc Loss: 1.0305, Time: 8.76 sec\n",
      "Epoch 39, Gen Loss: 1.3717, Disc Loss: 1.0448, Time: 8.70 sec\n",
      "Epoch 40, Gen Loss: 1.6236, Disc Loss: 0.9529, Time: 8.77 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Gen Loss: 1.2827, Disc Loss: 1.0768, Time: 10.84 sec\n",
      "Epoch 42, Gen Loss: 1.3322, Disc Loss: 1.0749, Time: 8.63 sec\n",
      "Epoch 43, Gen Loss: 1.2927, Disc Loss: 1.1098, Time: 8.58 sec\n",
      "Epoch 44, Gen Loss: 1.1380, Disc Loss: 1.1841, Time: 8.71 sec\n",
      "Epoch 45, Gen Loss: 1.3517, Disc Loss: 0.9857, Time: 10.96 sec\n",
      "Epoch 46, Gen Loss: 1.2959, Disc Loss: 1.1315, Time: 9.52 sec\n",
      "Epoch 47, Gen Loss: 1.3205, Disc Loss: 1.0485, Time: 8.70 sec\n",
      "Epoch 48, Gen Loss: 1.2265, Disc Loss: 1.1134, Time: 10.79 sec\n",
      "Epoch 49, Gen Loss: 1.2047, Disc Loss: 1.1587, Time: 8.73 sec\n",
      "Epoch 50, Gen Loss: 1.2365, Disc Loss: 1.2012, Time: 8.72 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "W0000 00:00:1724219763.218347   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.219201   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.220453   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.221231   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.222240   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.223060   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.224330   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.225945   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.227969   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.230115   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.232368   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.241751   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.242597   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.243388   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.244170   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.244947   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.246347   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.251841   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.256653   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.257540   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.258333   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.259135   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.259920   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.260887   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.261862   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724219763.262914   30730 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 저장 경로 설정\n",
    "SAVE_DIR = './cgan_results'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(SAVE_DIR, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(SAVE_DIR, 'models'), exist_ok=True)\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
    "train_images = (train_images.astype('float32') - 127.5) / 127.5  # 이미지를 [-1, 1]로 정규화\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# 생성자 모델 정의\n",
    "def make_generator_model():\n",
    "    noise_input = layers.Input(shape=(100,))\n",
    "    label_input = layers.Input(shape=(10,))\n",
    "    \n",
    "    x = layers.Concatenate()([noise_input, label_input])\n",
    "    x = layers.Dense(8*8*256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Reshape((8, 8, 256))(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "    model = tf.keras.Model([noise_input, label_input], x)\n",
    "    return model\n",
    "\n",
    "# 판별자 모델 정의\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[32, 32, 13]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "# 손실 함수 정의\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "# 모델 생성\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "# 옵티마이저 초기화\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    noise = tf.random.normal([batch_size, 100])\n",
    "    \n",
    "    # 이미지를 float32로 변환\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    \n",
    "    # 원-핫 인코딩된 레이블 생성\n",
    "    one_hot_labels = tf.one_hot(tf.squeeze(labels), depth=10)\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator([noise, one_hot_labels], training=True)\n",
    "\n",
    "        # 레이블을 이미지와 결합\n",
    "        label_channels = tf.repeat(tf.expand_dims(one_hot_labels, axis=1), repeats=32, axis=1)\n",
    "        label_channels = tf.repeat(tf.expand_dims(label_channels, axis=2), repeats=32, axis=2)\n",
    "        \n",
    "        real_input = tf.concat([images, label_channels], axis=3)\n",
    "        fake_input = tf.concat([generated_images, label_channels], axis=3)\n",
    "\n",
    "        real_output = discriminator(real_input, training=True)\n",
    "        fake_output = discriminator(fake_input, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input, test_labels):\n",
    "    predictions = model([test_input, test_labels], training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((predictions[i, :, :, :] + 1) / 2.0)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Class {tf.argmax(test_labels[i])}')\n",
    "\n",
    "    plt.savefig(os.path.join(SAVE_DIR, 'images', f'image_at_epoch_{epoch:04d}.png'))\n",
    "    plt.close()\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    history = []\n",
    "    \n",
    "    # 테스트용 입력 생성\n",
    "    num_examples_to_generate = 16\n",
    "    test_noise = tf.random.normal([num_examples_to_generate, 100])\n",
    "    test_labels = tf.range(0, 10, delta=1)\n",
    "    test_labels = tf.concat([test_labels, tf.random.uniform([6], minval=0, maxval=10, dtype=tf.int32)], axis=0)\n",
    "    test_labels = tf.one_hot(test_labels, depth=10)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "\n",
    "        for image_batch, label_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(image_batch, label_batch)\n",
    "            epoch_gen_loss.append(gen_loss)\n",
    "            epoch_disc_loss.append(disc_loss)\n",
    "\n",
    "        # 에포크 평균 손실 계산\n",
    "        avg_gen_loss = tf.reduce_mean(epoch_gen_loss)\n",
    "        avg_disc_loss = tf.reduce_mean(epoch_disc_loss)\n",
    "        \n",
    "        history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'gen_loss': avg_gen_loss.numpy(),\n",
    "            'disc_loss': avg_disc_loss.numpy(),\n",
    "            'time': time.time() - start\n",
    "        })\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Gen Loss: {avg_gen_loss:.4f}, Disc Loss: {avg_disc_loss:.4f}, Time: {time.time()-start:.2f} sec')\n",
    "\n",
    "        # 에포크마다 이미지 생성 및 저장\n",
    "        generate_and_save_images(generator, epoch + 1, test_noise, test_labels)\n",
    "        \n",
    "        # 10 에포크마다 모델 저장\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            generator.save(os.path.join(SAVE_DIR, 'models', f'generator_epoch_{epoch+1}.h5'))\n",
    "            discriminator.save(os.path.join(SAVE_DIR, 'models', f'discriminator_epoch_{epoch+1}.h5'))\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epochs, it, seed)\n",
    "    \n",
    "    # 학습 히스토리 저장\n",
    "    np.save(os.path.join(SAVE_DIR, 'training_history.npy'), history)\n",
    "    \n",
    "    # 학습 히스토리 그래프 생성 및 저장\n",
    "    plot_history(history)\n",
    "\n",
    "def plot_history(history):\n",
    "    gen_loss = [h['gen_loss'] for h in history]\n",
    "    disc_loss = [h['disc_loss'] for h in history]\n",
    "    epochs = [h['epoch'] for h in history]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, gen_loss, label='Generator Loss')\n",
    "    plt.plot(epochs, disc_loss, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training History')\n",
    "    plt.savefig(os.path.join(SAVE_DIR, 'training_history.png'))\n",
    "    plt.close()\n",
    "\n",
    "# 모델 학습\n",
    "EPOCHS = 50\n",
    "train(train_dataset, EPOCHS)\n",
    "\n",
    "# 학습된 모델을 사용하여 특정 클래스의 이미지 생성\n",
    "def generate_specific_class(class_num):\n",
    "    noise = tf.random.normal([1, 100])\n",
    "    one_hot_label = tf.one_hot([class_num], depth=10)\n",
    "    generated_image = generator([noise, one_hot_label], training=False)\n",
    "    \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow((generated_image[0, :, :, :] + 1) / 2.0)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Generated image for class {class_num}')\n",
    "    plt.savefig(os.path.join(SAVE_DIR, f'generated_class_{class_num}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# 클래스 0부터 9까지의 이미지 생성\n",
    "for i in range(10):\n",
    "    generate_specific_class(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 100])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "seed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 저장 경로 설정\n",
    "SAVE_DIR = './cgan_results'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(SAVE_DIR, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(SAVE_DIR, 'models'), exist_ok=True)\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
    "train_images = (train_images.astype('float32') - 127.5) / 127.5  # 이미지를 [-1, 1]로 정규화\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# 생성자 모델 정의\n",
    "def make_generator_model():\n",
    "    noise_input = layers.Input(shape=(100,))\n",
    "    label_input = layers.Input(shape=(10,))\n",
    "    \n",
    "    x = layers.Concatenate()([noise_input, label_input])\n",
    "    x = layers.Dense(8*8*256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Reshape((8, 8, 256))(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "    model = tf.keras.Model([noise_input, label_input], x)\n",
    "    return model\n",
    "\n",
    "# 판별자 모델 정의\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[32, 32, 13]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "# 손실 함수 정의\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "# 모델 생성\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "# 옵티마이저 초기화\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    noise = tf.random.normal([batch_size, 100])\n",
    "    \n",
    "    # 이미지를 float32로 변환\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    \n",
    "    # 원-핫 인코딩된 레이블 생성\n",
    "    one_hot_labels = tf.one_hot(tf.squeeze(labels), depth=10)\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator([noise, one_hot_labels], training=True)\n",
    "\n",
    "        # 레이블을 이미지와 결합\n",
    "        label_channels = tf.repeat(tf.expand_dims(one_hot_labels, axis=1), repeats=32, axis=1)\n",
    "        label_channels = tf.repeat(tf.expand_dims(label_channels, axis=2), repeats=32, axis=2)\n",
    "        \n",
    "        real_input = tf.concat([images, label_channels], axis=3)\n",
    "        fake_input = tf.concat([generated_images, label_channels], axis=3)\n",
    "\n",
    "        real_output = discriminator(real_input, training=True)\n",
    "        fake_output = discriminator(fake_input, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '/home/faith/workspace/cifar/training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_history(history):\n",
    "    gen_loss = [h['gen_loss'] for h in history]\n",
    "    disc_loss = [h['disc_loss'] for h in history]\n",
    "    epochs = [h['epoch'] for h in history]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, gen_loss, label='Generator Loss')\n",
    "    plt.plot(epochs, disc_loss, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training History')\n",
    "    plt.savefig(os.path.join(SAVE_DIR, 'training_history.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_and_save_images(model, epoch, test_input, test_labels):\n",
    "    predictions = model([test_input, test_labels], training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((predictions[i, :, :, :] + 1) / 2.0)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Class {tf.argmax(test_labels[i])}')\n",
    "\n",
    "    plt.savefig(os.path.join(SAVE_DIR, 'images', f'image_at_epoch_{epoch:04d}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6    # matlab 차트의 기본 크기를 15,6으로 지정해 줍니다.\n",
    "\n",
    "def draw_train_history(history, epoch):\n",
    "    # summarize history for loss  \n",
    "    plt.subplot(211)  \n",
    "    plt.plot(history['gen_loss'])  \n",
    "    plt.plot(history['disc_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('batch iters')  \n",
    "    plt.legend(['gen_loss', 'disc_loss'], loc='upper left')  \n",
    "\n",
    "    # summarize history for accuracy  \n",
    "    plt.subplot(212)  \n",
    "    plt.plot(history['fake_accuracy'])  \n",
    "    plt.plot(history['real_accuracy'])  \n",
    "    plt.title('discriminator accuracy')  \n",
    "    plt.ylabel('accuracy')  \n",
    "    plt.xlabel('batch iters')  \n",
    "    plt.legend(['fake_accuracy', 'real_accuracy'], loc='upper left')  \n",
    "    \n",
    "    # training_history 디렉토리에 epoch별로 그래프를 이미지 파일로 저장합니다.\n",
    "    plt.savefig('/home/faith/workspace/cifar/training_history/train_history_{:04d}.png'\n",
    "                    .format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, epochs, save_every):\n",
    "    history = {'gen_loss':[], 'disc_loss':[], 'real_accuracy':[], 'fake_accuracy':[]}\n",
    "    \n",
    "    # 테스트용 입력 생성\n",
    "    num_examples_to_generate = 16\n",
    "    test_noise = tf.random.normal([num_examples_to_generate, 100])\n",
    "    test_labels = tf.range(0, 10, delta=1)\n",
    "    test_labels = tf.concat([test_labels, tf.random.uniform([6], minval=0, maxval=10, dtype=tf.int32)], axis=0)\n",
    "    test_labels = tf.one_hot(test_labels, depth=10)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "\n",
    "        for image_batch, label_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(image_batch, label_batch)\n",
    "            epoch_gen_loss.append(gen_loss)\n",
    "            epoch_disc_loss.append(disc_loss)\n",
    "\n",
    "        # 에포크 평균 손실 계산\n",
    "        avg_gen_loss = tf.reduce_mean(epoch_gen_loss)\n",
    "        avg_disc_loss = tf.reduce_mean(epoch_disc_loss)\n",
    "        \n",
    "        history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'gen_loss': avg_gen_loss.numpy(),\n",
    "            'disc_loss': avg_disc_loss.numpy(),\n",
    "            'time': time.time() - start\n",
    "        })\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Gen Loss: {avg_gen_loss:.4f}, Disc Loss: {avg_disc_loss:.4f}, Time: {time.time()-start:.2f} sec')\n",
    "\n",
    "        # 에포크마다 이미지 생성 및 저장\n",
    "        generate_and_save_images(generator, epoch + 1, test_noise, test_labels)\n",
    "        \n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "    \n",
    "    # 학습 히스토리 저장\n",
    "    np.save(os.path.join(SAVE_DIR, 'training_history.npy'), history)\n",
    "    \n",
    "    # 학습 히스토리 그래프 생성 및 저장\n",
    "    plot_history(history)\n",
    "\n",
    "def plot_history(history):\n",
    "    gen_loss = [h['gen_loss'] for h in history]\n",
    "    disc_loss = [h['disc_loss'] for h in history]\n",
    "    epochs = [h['epoch'] for h in history]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, gen_loss, label='Generator Loss')\n",
    "    plt.plot(epochs, disc_loss, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training History')\n",
    "    plt.savefig(os.path.join(SAVE_DIR, 'training_history.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 학습된 모델을 사용하여 특정 클래스의 이미지 생성\n",
    "def generate_specific_class(class_num):\n",
    "    noise = tf.random.normal([1, 100])\n",
    "    one_hot_label = tf.one_hot([class_num], depth=10)\n",
    "    generated_image = generator([noise, one_hot_label], training=False)\n",
    "    \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow((generated_image[0, :, :, :] + 1) / 2.0)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Generated image for class {class_num}')\n",
    "    plt.savefig(os.path.join(SAVE_DIR, f'generated_class_{class_num}.png'))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gen Loss: 1.4216, Disc Loss: 1.0050, Time: 11.54 sec\n",
      "Epoch 2, Gen Loss: 1.3224, Disc Loss: 1.1014, Time: 13.81 sec\n",
      "Epoch 3, Gen Loss: 1.3320, Disc Loss: 1.0300, Time: 10.44 sec\n",
      "Epoch 4, Gen Loss: 1.3161, Disc Loss: 1.0808, Time: 10.85 sec\n",
      "Epoch 5, Gen Loss: 1.3832, Disc Loss: 1.0459, Time: 13.62 sec\n",
      "Epoch 6, Gen Loss: 1.4459, Disc Loss: 1.0321, Time: 8.26 sec\n",
      "Epoch 7, Gen Loss: 1.3947, Disc Loss: 1.0752, Time: 8.44 sec\n",
      "Epoch 8, Gen Loss: 1.2744, Disc Loss: 1.0775, Time: 11.45 sec\n",
      "Epoch 9, Gen Loss: 1.2456, Disc Loss: 1.0985, Time: 8.34 sec\n",
      "Epoch 10, Gen Loss: 1.2840, Disc Loss: 1.1147, Time: 8.24 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Gen Loss: 1.2301, Disc Loss: 1.1135, Time: 8.56 sec\n",
      "Epoch 12, Gen Loss: 1.3089, Disc Loss: 1.1302, Time: 11.44 sec\n",
      "Epoch 13, Gen Loss: 1.2891, Disc Loss: 1.0748, Time: 8.29 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 15:09:23.904461: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Gen Loss: 1.3033, Disc Loss: 1.0976, Time: 8.35 sec\n",
      "Epoch 15, Gen Loss: 1.3096, Disc Loss: 1.0893, Time: 8.85 sec\n",
      "Epoch 16, Gen Loss: 1.3835, Disc Loss: 1.0895, Time: 8.61 sec\n",
      "Epoch 17, Gen Loss: 1.3289, Disc Loss: 1.0668, Time: 8.27 sec\n",
      "Epoch 18, Gen Loss: 1.3865, Disc Loss: 1.0539, Time: 8.40 sec\n",
      "Epoch 19, Gen Loss: 1.2637, Disc Loss: 1.1221, Time: 11.67 sec\n",
      "Epoch 20, Gen Loss: 1.4026, Disc Loss: 0.9913, Time: 8.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Gen Loss: 1.3136, Disc Loss: 1.1300, Time: 8.31 sec\n",
      "Epoch 22, Gen Loss: 1.3746, Disc Loss: 1.1071, Time: 8.43 sec\n",
      "Epoch 23, Gen Loss: 1.3761, Disc Loss: 1.0331, Time: 11.50 sec\n",
      "Epoch 24, Gen Loss: 1.3092, Disc Loss: 1.0647, Time: 8.63 sec\n",
      "Epoch 25, Gen Loss: 1.2727, Disc Loss: 1.0866, Time: 8.58 sec\n",
      "Epoch 26, Gen Loss: 1.2561, Disc Loss: 1.1121, Time: 10.90 sec\n",
      "Epoch 27, Gen Loss: 1.2184, Disc Loss: 1.0921, Time: 8.89 sec\n",
      "Epoch 28, Gen Loss: 1.2770, Disc Loss: 1.1291, Time: 11.13 sec\n",
      "Epoch 29, Gen Loss: 1.3765, Disc Loss: 1.0387, Time: 9.96 sec\n",
      "Epoch 30, Gen Loss: 1.3557, Disc Loss: 1.0690, Time: 10.96 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Gen Loss: 1.3531, Disc Loss: 1.0996, Time: 10.48 sec\n",
      "Epoch 32, Gen Loss: 1.4064, Disc Loss: 1.0290, Time: 10.86 sec\n",
      "Epoch 33, Gen Loss: 1.3881, Disc Loss: 1.0454, Time: 13.31 sec\n",
      "Epoch 34, Gen Loss: 1.3089, Disc Loss: 1.0754, Time: 10.87 sec\n",
      "Epoch 35, Gen Loss: 1.3514, Disc Loss: 1.1148, Time: 10.93 sec\n",
      "Epoch 36, Gen Loss: 1.3794, Disc Loss: 1.0927, Time: 13.72 sec\n",
      "Epoch 37, Gen Loss: 1.3134, Disc Loss: 1.0893, Time: 11.25 sec\n",
      "Epoch 38, Gen Loss: 1.2937, Disc Loss: 1.1133, Time: 13.79 sec\n",
      "Epoch 39, Gen Loss: 1.3084, Disc Loss: 1.0736, Time: 11.29 sec\n",
      "Epoch 40, Gen Loss: 1.3994, Disc Loss: 1.0359, Time: 11.22 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Gen Loss: 1.3218, Disc Loss: 1.1148, Time: 13.75 sec\n",
      "Epoch 42, Gen Loss: 1.2406, Disc Loss: 1.1546, Time: 11.22 sec\n",
      "Epoch 43, Gen Loss: 1.2436, Disc Loss: 1.0712, Time: 11.22 sec\n",
      "Epoch 44, Gen Loss: 1.2723, Disc Loss: 1.1306, Time: 13.52 sec\n",
      "Epoch 45, Gen Loss: 1.2347, Disc Loss: 1.0865, Time: 8.52 sec\n",
      "Epoch 46, Gen Loss: 1.2813, Disc Loss: 1.0834, Time: 9.79 sec\n",
      "Epoch 47, Gen Loss: 1.2717, Disc Loss: 1.1633, Time: 13.30 sec\n",
      "Epoch 48, Gen Loss: 1.2553, Disc Loss: 1.0961, Time: 8.58 sec\n",
      "Epoch 49, Gen Loss: 1.2308, Disc Loss: 1.1184, Time: 8.57 sec\n",
      "Epoch 50, Gen Loss: 1.3509, Disc Loss: 1.0760, Time: 8.57 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 학습\n",
    "EPOCHS = 50\n",
    "save_every = 5\n",
    "\n",
    "train(train_dataset, EPOCHS)\n",
    "\n",
    "# 클래스 0부터 9까지의 이미지 생성\n",
    "for i in range(10):\n",
    "    generate_specific_class(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, epochs, save_every):\n",
    "    history = []\n",
    "    \n",
    "    # 테스트용 입력 생성\n",
    "    num_examples_to_generate = 16\n",
    "    test_noise = tf.random.normal([num_examples_to_generate, 100])\n",
    "    test_labels = tf.range(0, 10, delta=1)\n",
    "    test_labels = tf.concat([test_labels, tf.random.uniform([6], minval=0, maxval=10, dtype=tf.int32)], axis=0)\n",
    "    test_labels = tf.one_hot(test_labels, depth=10)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "\n",
    "        for image_batch, label_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(image_batch, label_batch)\n",
    "            epoch_gen_loss.append(gen_loss)\n",
    "            epoch_disc_loss.append(disc_loss)\n",
    "\n",
    "        # 에포크 평균 손실 계산\n",
    "        avg_gen_loss = tf.reduce_mean(epoch_gen_loss)\n",
    "        avg_disc_loss = tf.reduce_mean(epoch_disc_loss)\n",
    "        \n",
    "        history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'gen_loss': avg_gen_loss.numpy(),\n",
    "            'disc_loss': avg_disc_loss.numpy(),\n",
    "            'time': time.time() - start\n",
    "        })\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Gen Loss: {avg_gen_loss:.4f}, Disc Loss: {avg_disc_loss:.4f}, Time: {time.time()-start:.2f} sec')\n",
    "\n",
    "        # 에포크마다 이미지 생성 및 저장\n",
    "        generate_and_save_images(generator, epoch + 1, test_noise, test_labels)\n",
    "        \n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    \n",
    "    # 학습 히스토리 저장\n",
    "    np.save(os.path.join(SAVE_DIR, 'training_history.npy'), history)\n",
    "    \n",
    "    # 학습 히스토리 그래프 생성 및 저장\n",
    "    plot_history(history)\n",
    "\n",
    "def plot_history(history):\n",
    "    gen_loss = [h['gen_loss'] for h in history]\n",
    "    disc_loss = [h['disc_loss'] for h in history]\n",
    "    epochs = [h['epoch'] for h in history]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, gen_loss, label='Generator Loss')\n",
    "    plt.plot(epochs, disc_loss, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training History')\n",
    "    plt.savefig(os.path.join(SAVE_DIR, 'training_history.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 학습된 모델을 사용하여 특정 클래스의 이미지 생성\n",
    "def generate_specific_class(class_num):\n",
    "    noise = tf.random.normal([1, 100])\n",
    "    one_hot_label = tf.one_hot([class_num], depth=10)\n",
    "    generated_image = generator([noise, one_hot_label], training=False)\n",
    "    \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow((generated_image[0, :, :, :] + 1) / 2.0)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Generated image for class {class_num}')\n",
    "    plt.savefig(os.path.join(SAVE_DIR, f'generated_class_{class_num}.png'))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gen Loss: 1.2391, Disc Loss: 1.1336, Time: 14.45 sec\n",
      "Epoch 2, Gen Loss: 1.2231, Disc Loss: 1.1224, Time: 10.66 sec\n",
      "Epoch 3, Gen Loss: 1.1666, Disc Loss: 1.1918, Time: 8.71 sec\n",
      "Epoch 4, Gen Loss: 1.2471, Disc Loss: 1.1846, Time: 11.52 sec\n",
      "Epoch 5, Gen Loss: 1.3173, Disc Loss: 1.0523, Time: 8.39 sec\n",
      "Epoch 6, Gen Loss: 1.2188, Disc Loss: 1.1916, Time: 8.28 sec\n",
      "Epoch 7, Gen Loss: 1.2135, Disc Loss: 1.1196, Time: 8.48 sec\n",
      "Epoch 8, Gen Loss: 1.1324, Disc Loss: 1.1801, Time: 11.63 sec\n",
      "Epoch 9, Gen Loss: 1.1063, Disc Loss: 1.1665, Time: 8.31 sec\n",
      "Epoch 10, Gen Loss: 1.1406, Disc Loss: 1.1790, Time: 8.33 sec\n",
      "Epoch 11, Gen Loss: 1.1977, Disc Loss: 1.1621, Time: 11.41 sec\n",
      "Epoch 12, Gen Loss: 1.2465, Disc Loss: 1.1427, Time: 8.59 sec\n",
      "Epoch 13, Gen Loss: 1.2387, Disc Loss: 1.1574, Time: 10.02 sec\n",
      "Epoch 14, Gen Loss: 1.2344, Disc Loss: 1.1300, Time: 9.53 sec\n",
      "Epoch 15, Gen Loss: 1.1864, Disc Loss: 1.1443, Time: 11.53 sec\n",
      "Epoch 16, Gen Loss: 1.2076, Disc Loss: 1.1256, Time: 8.26 sec\n",
      "Epoch 17, Gen Loss: 1.2991, Disc Loss: 1.1284, Time: 8.26 sec\n",
      "Epoch 18, Gen Loss: 1.3789, Disc Loss: 1.0305, Time: 11.31 sec\n",
      "Epoch 19, Gen Loss: 1.2904, Disc Loss: 1.1466, Time: 8.84 sec\n",
      "Epoch 20, Gen Loss: 1.2093, Disc Loss: 1.1343, Time: 8.27 sec\n",
      "Epoch 21, Gen Loss: 1.1771, Disc Loss: 1.1692, Time: 10.19 sec\n",
      "Epoch 22, Gen Loss: 1.2199, Disc Loss: 1.1562, Time: 11.72 sec\n",
      "Epoch 23, Gen Loss: 1.1853, Disc Loss: 1.1057, Time: 8.46 sec\n",
      "Epoch 24, Gen Loss: 1.1787, Disc Loss: 1.1472, Time: 8.30 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 15:26:27.790893: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Gen Loss: 1.2128, Disc Loss: 1.1564, Time: 12.29 sec\n",
      "Epoch 26, Gen Loss: 1.1681, Disc Loss: 1.1827, Time: 8.35 sec\n",
      "Epoch 27, Gen Loss: 1.1880, Disc Loss: 1.1698, Time: 8.15 sec\n",
      "Epoch 28, Gen Loss: 1.1512, Disc Loss: 1.1361, Time: 8.55 sec\n",
      "Epoch 29, Gen Loss: 1.1389, Disc Loss: 1.1900, Time: 11.63 sec\n",
      "Epoch 30, Gen Loss: 1.2089, Disc Loss: 1.1074, Time: 8.37 sec\n",
      "Epoch 31, Gen Loss: 1.1540, Disc Loss: 1.1718, Time: 8.34 sec\n",
      "Epoch 32, Gen Loss: 1.1229, Disc Loss: 1.1941, Time: 8.55 sec\n",
      "Epoch 33, Gen Loss: 1.1657, Disc Loss: 1.1366, Time: 11.78 sec\n",
      "Epoch 34, Gen Loss: 1.1595, Disc Loss: 1.1547, Time: 8.36 sec\n",
      "Epoch 35, Gen Loss: 1.2051, Disc Loss: 1.1092, Time: 8.33 sec\n",
      "Epoch 36, Gen Loss: 1.1469, Disc Loss: 1.1718, Time: 11.51 sec\n",
      "Epoch 37, Gen Loss: 1.2249, Disc Loss: 1.0984, Time: 9.93 sec\n",
      "Epoch 38, Gen Loss: 1.2166, Disc Loss: 1.2347, Time: 8.25 sec\n",
      "Epoch 39, Gen Loss: 1.1846, Disc Loss: 1.2031, Time: 9.16 sec\n",
      "Epoch 40, Gen Loss: 1.2281, Disc Loss: 1.1205, Time: 11.83 sec\n",
      "Epoch 41, Gen Loss: 1.1232, Disc Loss: 1.1750, Time: 8.39 sec\n",
      "Epoch 42, Gen Loss: 1.1211, Disc Loss: 1.1993, Time: 8.33 sec\n",
      "Epoch 43, Gen Loss: 1.1313, Disc Loss: 1.1735, Time: 8.71 sec\n",
      "Epoch 44, Gen Loss: 1.1116, Disc Loss: 1.1865, Time: 8.92 sec\n",
      "Epoch 45, Gen Loss: 1.1707, Disc Loss: 1.1513, Time: 10.36 sec\n",
      "Epoch 46, Gen Loss: 1.0649, Disc Loss: 1.2631, Time: 11.76 sec\n",
      "Epoch 47, Gen Loss: 1.1095, Disc Loss: 1.1987, Time: 10.04 sec\n",
      "Epoch 48, Gen Loss: 1.1052, Disc Loss: 1.1661, Time: 8.41 sec\n",
      "Epoch 49, Gen Loss: 1.0614, Disc Loss: 1.1926, Time: 10.23 sec\n",
      "Epoch 50, Gen Loss: 1.0860, Disc Loss: 1.1810, Time: 13.00 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 학습\n",
    "EPOCHS = 50\n",
    "save_every = 5\n",
    "\n",
    "train(train_dataset, EPOCHS, save_every)\n",
    "\n",
    "# 클래스 0부터 9까지의 이미지 생성\n",
    "for i in range(10):\n",
    "    generate_specific_class(i)\n",
    "\n",
    "# airplane\n",
    "# automobile\n",
    "# bird\n",
    "# cat\n",
    "# deer\n",
    "# dog\n",
    "# frog\n",
    "# horse\n",
    "# ship\n",
    "# truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
